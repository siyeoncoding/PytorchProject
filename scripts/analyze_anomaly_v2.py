# scripts/analyze_anomaly_v2.py
import os
import re
import html
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# ============================================================
#  ê³µí†µ ìœ í‹¸: ì œëª©/í…ìŠ¤íŠ¸ í´ë¦¬ë‹ (ì¤‘ë³µ ì§‘ê³„ìš©)
# ============================================================
def clean_title(text: str) -> str:
    """
    HTML íƒœê·¸ ì œê±° + HTML entities í•´ì œ + ê³µë°± ì •ë¦¬
    (preprocess_v2.py ì˜ clean_title ê³¼ ë™ì¼ ì»¨ì…‰)
    """
    if pd.isna(text):
        return ""
    text = html.unescape(str(text))
    text = re.sub(r"<[^>]+>", " ", text)   # íƒœê·¸ ì œê±°
    text = re.sub(r"\s+", " ", text)       # ê³µë°± ì •ë¦¬
    return text.strip()


# ============================================================
#  Threshold ì¬ê³„ì‚° (ì˜µì…˜: ë¶„ì„ìš©)
# ============================================================
def compute_thresholds(scores: np.ndarray, top_percent: float = 5.0, mad_k: float = 3.0):
    """
    recon_loss ë°°ì—´(scores)ì„ ë°›ì•„ì„œ
    - TOP N% (ìƒìœ„ í¼ì„¼íƒ€ì¼)
    - IQR (Q3 + 1.5*IQR)
    - MAD (median + k * MAD)
    ê¸°ì¤€ thresholdë¥¼ ê³„ì‚°í•´ì„œ ë¦¬í„´
    """
    scores = np.asarray(scores, dtype=float)

    # TOP N% ê¸°ì¤€
    top_thr = np.quantile(scores, 1.0 - top_percent / 100.0)

    # IQR ê¸°ì¤€ (Q3 + 1.5*IQR)
    q1 = np.quantile(scores, 0.25)
    q3 = np.quantile(scores, 0.75)
    iqr = q3 - q1
    iqr_thr = q3 + 1.5 * iqr

    # MAD ê¸°ì¤€ (median + k * MAD)
    median = np.median(scores)
    mad = np.median(np.abs(scores - median))
    mad_thr = median + mad_k * mad

    thresholds = {
        "topN": top_thr,
        "iqr": iqr_thr,
        "mad": mad_thr,
        "q1": q1,
        "q3": q3,
        "iqr_raw": iqr,
        "median": median,
        "mad_raw": mad,
    }
    return thresholds


# ============================================================
#  Plot 1: ê°€ê²© + anomaly intensity (recon_loss)
# ============================================================
def plot_price_anomaly_intensity(
    df: pd.DataFrame,
    anomaly_flag_col: str = "is_anomaly_iqr",
    save_path: str = "../figures/price_anomaly_intensity_v2.png",
):
    """
    ì¢…ê°€ + recon_loss + ì´ìƒì¹˜ êµ¬ê°„ì„ í•œ ë²ˆì— ë³´ëŠ” í”Œë¡¯
    - ì™¼ìª½ yì¶•: ì¢…ê°€
    - ì˜¤ë¥¸ìª½ yì¶•: recon_loss
    - ì´ìƒì¹˜ êµ¬ê°„: ë¹¨ê°„ ì (or marker)
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    df_plot = df.copy()
    df_plot["ë‚ ì§œ_dt"] = pd.to_datetime(df_plot["ë‚ ì§œ"])

    fig, ax1 = plt.subplots(figsize=(14, 6))

    # ê°€ê²© (ì™¼ìª½ yì¶•)
    ax1.plot(df_plot["ë‚ ì§œ_dt"], df_plot["ì¢…ê°€"], label="ì¢…ê°€", linewidth=1.5)
    ax1.set_xlabel("ë‚ ì§œ")
    ax1.set_ylabel("ì¢…ê°€")

    # recon_loss (ì˜¤ë¥¸ìª½ yì¶•)
    ax2 = ax1.twinx()
    ax2.plot(df_plot["ë‚ ì§œ_dt"], df_plot["recon_loss"], label="recon_loss", alpha=0.5, linewidth=1.0)
    ax2.set_ylabel("reconstruction loss")

    # ì´ìƒì¹˜ í¬ì¸íŠ¸ ê°•ì¡°
    if anomaly_flag_col in df_plot.columns:
        anomalies = df_plot[df_plot[anomaly_flag_col]]
        ax2.scatter(
            anomalies["ë‚ ì§œ_dt"],
            anomalies["recon_loss"],
            marker="o",
            s=50,
            edgecolor="red",
            facecolor="none",
            linewidth=1.5,
            label="Anomaly"
        )

    # ë²”ë¡€
    lines_1, labels_1 = ax1.get_legend_handles_labels()
    lines_2, labels_2 = ax2.get_legend_handles_labels()
    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc="upper left")

    plt.title(f"Price & Anomaly Intensity (ê¸°ì¤€: {anomaly_flag_col})")
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

    print(f"[SAVE] price + anomaly intensity â†’ {save_path}")


# ============================================================
#  Plot 2: ì—°/ì›” anomaly heatmap
# ============================================================
def plot_monthly_anomaly_heatmap(
    df: pd.DataFrame,
    anomaly_flag_col: str = "is_anomaly_iqr",
    save_path: str = "../figures/monthly_anomaly_heatmap_v2.png",
):
    """
    ì—°-ì›” ë‹¨ìœ„ë¡œ ì´ìƒì¹˜ ì¼ìˆ˜ ì¹´ìš´íŠ¸ë¥¼ heatmap ìœ¼ë¡œ ì‹œê°í™”
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    df_hm = df.copy()
    df_hm["ë‚ ì§œ_dt"] = pd.to_datetime(df_hm["ë‚ ì§œ"])
    df_hm["year"] = df_hm["ë‚ ì§œ_dt"].dt.year
    df_hm["month"] = df_hm["ë‚ ì§œ_dt"].dt.month

    if anomaly_flag_col in df_hm.columns:
        df_hm["is_anomaly"] = df_hm[anomaly_flag_col].astype(int)
    else:
        df_hm["is_anomaly"] = 0

    monthly = (
        df_hm.groupby(["year", "month"])["is_anomaly"]
        .sum()
        .reset_index()
        .pivot(index="year", columns="month", values="is_anomaly")
        .fillna(0)
        .astype(int)
    )

    plt.figure(figsize=(10, 4))
    sns.heatmap(
        monthly,
        annot=True,
        fmt="d",
        cmap="Reds",
        cbar_kws={"label": "Anomaly Days"},
    )
    plt.title(f"Monthly Anomaly Heatmap (ê¸°ì¤€: {anomaly_flag_col})")
    plt.xlabel("ì›”")
    plt.ylabel("ì—°ë„")
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

    print(f"[SAVE] monthly anomaly heatmap â†’ {save_path}")


# ============================================================
#  ë‰´ìŠ¤ raw ì—ì„œ ë‚ ì§œë³„ Top-5 ì œëª©(ì¤‘ë³µ ì¹´ìš´íŠ¸) ê³„ì‚°
# ============================================================
def build_daily_top_titles(
    news_raw_path: str = "../data/raw/news_raw.csv",
    top_k: int = 5,
):
    """
    news_raw.csv ì—ì„œ ë‚ ì§œë³„ë¡œ
      - ì œëª© clean
      - ë™ì¼ ì œëª© ì¤‘ë³µ ì¹´ìš´íŠ¸
      - ë‚ ì§œë³„ Top-K (ì œëª©, count) list ìƒì„±
    return: dict[date(íŒŒì´ì¬ date)] = [(title, count), ...]
    """
    if not os.path.exists(news_raw_path):
        print(f"[WARN] news_raw file not found: {news_raw_path}")
        return {}

    news = pd.read_csv(news_raw_path, encoding="utf-8-sig")

    if "date" not in news.columns or "title" not in news.columns:
        print("[WARN] news_raw.csv ì— 'date' ë˜ëŠ” 'title' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    news["date_dt"] = pd.to_datetime(news["date"]).dt.date
    news["title"] = news["title"].fillna("")
    news["title_clean"] = news["title"].apply(clean_title)
    news = news[news["title_clean"] != ""]  # ë¹ˆ ì œëª© ì œê±°

    daily_title_dict = {}

    for d, group in news.groupby("date_dt"):
        # clean_title ê¸°ì¤€ìœ¼ë¡œ count
        cnt = group.groupby("title_clean").size().sort_values(ascending=False)

        top_list = []
        for clean_t, c in cnt.head(top_k).items():
            # ëŒ€í‘œ ì›ë¬¸ ì œëª© í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
            raw_example = group[group["title_clean"] == clean_t]["title"].iloc[0]
            top_list.append((raw_example, int(c)))

        daily_title_dict[d] = top_list

    print(f"[STEP] Built daily top-{top_k} titles from news_raw (days: {len(daily_title_dict)})")
    return daily_title_dict


# ============================================================
#  ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
# ============================================================
def analyze_anomaly_v2(
    anomaly_csv_path: str = "../data/processed/anomaly_scores_v2.csv",
    news_raw_path: str = "../data/raw/news_raw.csv",
    anomaly_flag_col: str = "is_anomaly_iqr",  # ê¸°ë³¸: IQR ê¸°ì¤€
    top_percent: float = 5.0,
    mad_k: float = 3.0,
    top_n_days: int = 20,
):
    print("========================")
    print("  Anomaly Analysis (v2) ")
    print("========================\n")

    # -----------------------------
    # 1) anomaly_scores_v2.csv ë¡œë“œ
    # -----------------------------
    if not os.path.exists(anomaly_csv_path):
        raise FileNotFoundError(f"anomaly_scores_v2.csv not found: {anomaly_csv_path}")

    df = pd.read_csv(anomaly_csv_path, encoding="utf-8-sig")

    if "ë‚ ì§œ" not in df.columns:
        raise KeyError("'ë‚ ì§œ' ì»¬ëŸ¼ì´ anomaly_scores_v2.csv ì— ì—†ìŠµë‹ˆë‹¤.")

    df["ë‚ ì§œ_dt"] = pd.to_datetime(df["ë‚ ì§œ"])
    df = df.sort_values("ë‚ ì§œ_dt").reset_index(drop=True)

    print("[STEP] Load anomaly_scores_v2")
    print(f" - shape: {df.shape}")
    print(f" - date range: {df['ë‚ ì§œ_dt'].min().date()} ~ {df['ë‚ ì§œ_dt'].max().date()}")

    if "recon_loss" not in df.columns:
        raise KeyError("'recon_loss' ì»¬ëŸ¼ì´ anomaly_scores_v2.csv ì— ì—†ìŠµë‹ˆë‹¤.")

    # -----------------------------
    # 2) Threshold ë‹¤ì‹œ ê³„ì‚° (ì˜µì…˜)
    # -----------------------------
    thresholds = compute_thresholds(df["recon_loss"].values, top_percent=top_percent, mad_k=mad_k)

    print("\n[INFO] Thresholds (recomputed from recon_loss)")
    print(f" - TOP {top_percent:.1f}% ê¸°ì¤€ threshold : {thresholds['topN']:.4f}")
    print(
        f" - IQR ê¸°ë°˜ threshold (Q3 + 1.5*IQR): {thresholds['iqr']:.4f} "
        f"(Q1={thresholds['q1']:.4f}, Q3={thresholds['q3']:.4f}, IQR={thresholds['iqr_raw']:.4f})"
    )
    print(
        f" - MAD ê¸°ë°˜ threshold (median + {mad_k:.1f} * MAD): {thresholds['mad']:.4f} "
        f"(median={thresholds['median']:.4f}, MAD={thresholds['mad_raw']:.4f})"
    )

    # -----------------------------
    # 3) anomaly flag ìš”ì•½
    # -----------------------------
    for col in ["is_anomaly_topN", "is_anomaly_iqr", "is_anomaly_mad"]:
        if col in df.columns:
            print(f" - {col}: {df[col].sum()} ê°œ / {len(df)}")

    if anomaly_flag_col not in df.columns:
        raise KeyError(f"'{anomaly_flag_col}' ì»¬ëŸ¼ì´ anomaly_scores_v2.csv ì— ì—†ìŠµë‹ˆë‹¤.")

    # -----------------------------
    # 4) ë‰´ìŠ¤ê°œìˆ˜ / ê³ ìœ ì œëª©ìˆ˜ ì „ì¼ ëŒ€ë¹„ ë³€í™”
    # -----------------------------
    if "ë‰´ìŠ¤ê°œìˆ˜" in df.columns:
        df["ë‰´ìŠ¤ê°œìˆ˜_diff"] = df["ë‰´ìŠ¤ê°œìˆ˜"].diff().fillna(0).astype(int)
    else:
        df["ë‰´ìŠ¤ê°œìˆ˜"] = 0
        df["ë‰´ìŠ¤ê°œìˆ˜_diff"] = 0

    if "ê³ ìœ ì œëª©ìˆ˜" in df.columns:
        df["ê³ ìœ ì œëª©ìˆ˜_diff"] = df["ê³ ìœ ì œëª©ìˆ˜"].diff().fillna(0).astype(int)
    else:
        df["ê³ ìœ ì œëª©ìˆ˜"] = 0
        df["ê³ ìœ ì œëª©ìˆ˜_diff"] = 0

    # -----------------------------
    # 5) ì´ìƒì¹˜ ì¼ì ì •ë ¬ (recon_loss ê¸°ì¤€)
    # -----------------------------
    anomalies = df[df[anomaly_flag_col]].copy()
    anomalies = anomalies.sort_values("recon_loss", ascending=False).reset_index(drop=True)

    print(f"\n[STEP] Top-{top_n_days} anomaly days (ê¸°ì¤€: {anomaly_flag_col}, ì •ë ¬: recon_loss ë‚´ë¦¼ì°¨ìˆœ)\n")

    # -----------------------------
    # 6) ë‚ ì§œë³„ Top-5 ë‰´ìŠ¤ ì œëª© ì‚¬ì „ êµ¬ì„±
    # -----------------------------
    daily_title_dict = build_daily_top_titles(news_raw_path=news_raw_path, top_k=5)

    # -----------------------------
    # 7) ìƒìœ„ Nê°œ ì´ìƒì¹˜ ë‚ ì§œ ìƒì„¸ ì¶œë ¥
    # -----------------------------
    for i in range(min(top_n_days, len(anomalies))):
        row = anomalies.iloc[i]
        d = row["ë‚ ì§œ_dt"].date()
        close_price = row.get("ì¢…ê°€", np.nan)
        recon_loss = row["recon_loss"]

        news_count = row.get("ë‰´ìŠ¤ê°œìˆ˜", 0)
        uniq_count = row.get("ê³ ìœ ì œëª©ìˆ˜", 0)
        news_diff = row.get("ë‰´ìŠ¤ê°œìˆ˜_diff", 0)
        uniq_diff = row.get("ê³ ìœ ì œëª©ìˆ˜_diff", 0)

        print("-------------------------------")
        print(f"ğŸ“Œ ë‚ ì§œ: {d} | ì¢…ê°€: {close_price} | recon_loss: {recon_loss:.4f}")
        print(
            f" - ë‰´ìŠ¤ê°œìˆ˜: {news_count} (ì „ì¼ ëŒ€ë¹„ {news_diff:+d}) "
            f"/ ê³ ìœ ì œëª©ìˆ˜: {uniq_count} (ì „ì¼ ëŒ€ë¹„ {uniq_diff:+d})"
        )

        # í•´ë‹¹ ë‚ ì§œì˜ Top-5 ë‰´ìŠ¤ ì œëª©
        titles = daily_title_dict.get(d, [])
        if not titles:
            print(" - í•´ë‹¹ ë‚ ì§œì˜ ë‰´ìŠ¤ ì—†ìŒ (news_raw ê¸°ì¤€)")
        else:
            print(" - Top ë‰´ìŠ¤ ì œëª©:")
            for j, (title, cnt) in enumerate(titles, start=1):
                print(f"   {j}. {title} (count={cnt})")

    print("\n[SUCCESS] Top-5 ë‰´ìŠ¤ ì œëª© + ë‰´ìŠ¤ ê°œìˆ˜ ë³€í™” ì¶œë ¥ ì™„ë£Œ.\n")

    # -----------------------------
    # 8) ì‹œê°í™” (intensity plot + heatmap)
    # -----------------------------
    print("[STEP] Plotting price + anomaly intensity...")
    plot_price_anomaly_intensity(
        df=df,
        anomaly_flag_col=anomaly_flag_col,
        save_path="../figures/price_anomaly_intensity_v2.png",
    )

    print("[STEP] Plotting monthly anomaly heatmap...")
    plot_monthly_anomaly_heatmap(
        df=df,
        anomaly_flag_col=anomaly_flag_col,
        save_path="../figures/monthly_anomaly_heatmap_v2.png",
    )

    print("\n[SUCCESS] Anomaly analysis v2 complete.\n")


# ============================================================
#  ì‹¤í–‰ë¶€
# ============================================================
if __name__ == "__main__":
    analyze_anomaly_v2(
        anomaly_csv_path="../data/processed/anomaly_scores_v2.csv",
        news_raw_path="../data/raw/news_raw.csv",
        anomaly_flag_col="is_anomaly_iqr",  # í•„ìš”í•˜ë©´ is_anomaly_topN, is_anomaly_mad ë¡œ ë°”ê¿”ë„ ë¨
        top_percent=5.0,
        mad_k=3.0,
        top_n_days=20,
    )
