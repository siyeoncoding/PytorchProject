# ğŸ“ˆ Multimodal AutoEncoder ê¸°ë°˜ ì‹œì¥ ì´ìƒì¹˜ íƒì§€ (Market Anomaly Detection)

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-1.13%2B-EE4C2C)
![KoBERT](https://img.shields.io/badge/Model-KoBERT-green)
![Status](https://img.shields.io/badge/Status-Active-success)

<b>ë³¸ í”„ë¡œì íŠ¸ëŠ” KOSPI ê°€ê²© ë°ì´í„°(ì •ëŸ‰)ì™€ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë°ì´í„°(ì •ì„±)ë¥¼ ê²°í•©í•œ  
ë©€í‹°ëª¨ë‹¬(Multimodal) AutoEncoder ê¸°ë°˜ <b>ì‹œì¥ ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ<b>ì…ë‹ˆë‹¤.

AutoEncoderì˜ ì¬êµ¬ì„± ì˜¤ì°¨(Reconstruction Error)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ  
ë¹„ì •ìƒì ì¸ ì‹œì¥ ì›€ì§ì„ì„ íƒì§€í•˜ê³ , í•´ë‹¹ ì‹œì ì˜ ì£¼ìš” ë‰´ìŠ¤(ì²« ë¬¸ì¥)ë¥¼ ì¶”ì¶œí•˜ì—¬  
ì‹œì¥ ë³€ë™ ì›ì¸ì„ ìë™ìœ¼ë¡œ ë¦¬í¬íŒ…í•©ë‹ˆë‹¤.

---

#  1. í”„ë¡œì íŠ¸ ê°œìš”

##  ëª©í‘œ
- ì£¼ê°€ì™€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ **ì‹œì¥ ì´ìƒì¹˜(Anomaly)ë¥¼ ìë™ íƒì§€**
- ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ë¶„ì„ì„ í™œìš©í•˜ì—¬ **ì‹œì¥ ë³€ë™ ì›ì¸ì„ ì„¤ëª…**
- ì´ìƒì¹˜ Top 20 ë‚ ì§œì— ëŒ€í•œ **ê°€ê²© ê·¸ë˜í”„ + ìš”ì•½ ë¦¬í¬íŠ¸ ìë™ ìƒì„±**
- ë©€í‹°ëª¨ë‹¬ AutoEncoder ê¸°ë°˜ Reconstruction ê¸°ë°˜ ì´ìƒ íƒì§€ ëª¨ë¸ êµ¬ì¶•

---

# 2. ì…ë ¥ ë°ì´í„°(Inputs)

##  2-1. ì •ëŸ‰ ë°ì´í„° (Quantitative)
| Feature | ì„¤ëª… |
|--------|------|
| close | KOSPI ì¢…ê°€ |
| return | ìˆ˜ìµë¥  |
| log_return | ë¡œê·¸ ìˆ˜ìµë¥  |
| volatility_10d | 10ì¼ ì´ë™ ë³€ë™ì„± |
| volume | ê±°ë˜ëŸ‰ |
[![img_1.png](img_1.png)](https://github.com/siyeoncoding/PytorchProject/issues/new)
â¡ ì´ 5ê°œ ìˆ˜ì¹˜í˜• Feature

##  2-2. í¬ë¡¤ë§ ë°ì´í„°
- ë„¤ì´ë²„ ë‰´ìŠ¤ API ìˆ˜ì§‘ 
- í•˜ë£¨ ì „ì²´ ë‰´ìŠ¤ ë¬¸ì¥ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³‘í•©
- â†’ KoBERT CLS Embedding (768ì°¨ì›)
<img width="1115" height="399" alt="Image" src="https://github.com/user-attachments/assets/67648d67-2e37-44f1-9283-bcc9abd349f3" />

### ìµœì¢… ì…ë ¥ êµ¬ì¡°
```
5 numerical features  
+ 768 KoBERT embedding  
= ì´ 773ì°¨ì› Feature Vector
```

---

# 3. ëª¨ë¸ êµ¬ì¡° (AutoEncoder)

```
Encoder: 773 â†’ 512 â†’ 256 â†’ 128 â†’ 64  
Decoder: 64 â†’ 128 â†’ 256 â†’ 512 â†’ 773  
Loss: MSE (Reconstruction Error)
```

ì •ìƒ ë°ì´í„°ë¥¼ ì˜ ë³µì›í•˜ê³ ,  
**ë³µì›ì´ ì–´ë ¤ìš´ ë‚ (ì˜¤ì°¨ â†‘)** ì„ **ì´ìƒì¹˜(Anomaly)** ë¡œ ê°„ì£¼.

---

# ğŸ” 4. ë°ì´í„° ë¶„í•  (6:2:2 ë¹„ìœ¨)

ì„±ëŠ¥ í–¥ìƒ ë° ì•ˆì •ì  ê²€ì¦ì„ ìœ„í•´ 6:2:2ë¡œ ë°ì´í„° ë¶„í• .

| êµ¬ë¶„ | ë¹„ìœ¨ | ì„¤ëª… |
|------|------|------|
| Train | 60% | ëª¨ë¸ í•™ìŠµ |
| Validation | 20% | í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ |
| Test | 20% | ìµœì¢… ì´ìƒì¹˜ íƒì§€ |

> ëœë¤ ì…”í”Œ ê¸°ë°˜ ë¶„í•  (`train_test_split` ì‚¬ìš©)

---

# 5. ì‹¤í—˜ ê²°ê³¼ (Hyperparameter Tuning)

Batch Sizeì— ë”°ë¥¸ í•™ìŠµ ê³¡ì„  ë¹„êµ.

## ğŸ”¹ Batch Size = 16  
![ae_training_curve_16batch.png](models%2Fautoencoder%2Fae_training_curve_16batch.png)

## ğŸ”¹ Batch Size = 32 (Baseline)
![ae_training_curve_32batch.png](models%2Fautoencoder%2Fae_training_curve_32batch.png)

## ğŸ”¹ Batch Size = 64  
![ae_training_curve_64batch.png](models%2Fautoencoder%2Fae_training_curve_64batch.png)

## ğŸ”¹ 6:2:2 ë¶„í•  ì‹¤í—˜
![ae_training_curve_622.png](models%2Fautoencoder%2Fae_training_curve_622.png)

### Observations
- Batch Size 32 â†’ ê°€ì¥ ì•ˆì •ì , ìµœì  ì„±ëŠ¥  
- Batch Size 16 â†’ ìˆ˜ë ´ ì†ë„ ëŠë¦¼  
- Batch Size 64 â†’ Validation Loss ì§„ë™ ì¦ê°€  
- 6:2:2 â†’ Train/Val ê· í˜• ì¢‹ì•„ ê³¼ì í•© ê°ì†Œ

---

# 6. ì´ìƒì¹˜ íƒì§€ ê²°ê³¼ (Top 20)

##  6-1. KOSPI ê°€ê²© + ì´ìƒì¹˜ ìœ„ì¹˜  
![A1_price_with_anomalies_top20.png](src%2Fanalysis%2Fanalysis%2Ffigures%2FA1_price_with_anomalies_top20.png)

ğŸ”´ ë¶‰ì€ ì  = Reconstruction Error ìƒìœ„ 20ê°œ ë‚ ì§œ

---

## 6-2. ì´ìƒì¹˜ Top 20 ìƒì„¸ ë‰´ìŠ¤ ìš”ì•½

### Page 1
![A2_top20_anomaly_summaries_part1.png](src%2Fanalysis%2Fanalysis%2Ffigures%2FA2_top20_anomaly_summaries_part1.png)

### Page 2
![A2_top20_anomaly_summaries_part2.png](src%2Fanalysis%2Fanalysis%2Ffigures%2FA2_top20_anomaly_summaries_part2.png)

### ë‚´ìš© ìš”ì•½
- ì´ìƒì¹˜ ë‚ ì§œëŠ” **ëŒ€ê·œëª¨ ìˆ˜ì£¼/ì „ìŸ/í™˜ìœ¨ ë³€ë™/ì •ì±… ì¶©ê²©** ë“± ì£¼ìš” ì´ë²¤íŠ¸ ì§‘ì¤‘
- ë‰´ìŠ¤ ì²« ë¬¸ì¥ìœ¼ë¡œ í•´ë‹¹ ì‹œì¥ ë°˜ì‘ì˜ ì›ì¸ ìœ ì¶”í•˜ê¸°
---

#  7. ê²°ë¡  (Conclusion)

- **ì •ëŸ‰ + ì •ì„± ê²°í•© ë©€í‹°ëª¨ë‹¬ AutoEncoder**ëŠ” ì‹œì¥ ì´ìƒ íƒì§€ì— íš¨ê³¼ì 
- KoBERT ì„ë² ë”©ì€ ì´ìƒì¹˜ êµ¬ë¶„ë ¥ í–¥ìƒì— ê¸°ì—¬
- KoBART ìš”ì•½ ëŒ€ì‹  â€œë‰´ìŠ¤ ì²« ë¬¸ì¥ ì¶”ì¶œ ë°©ì‹â€ ì‚¬ìš©í•˜ì—¬ ì†ë„ ìµœì í™”
- 6:2:2 ë¶„í• ì—ì„œ ëª¨ë¸ ì•ˆì •ì  ìˆ˜ë ´ & ê³¼ì í•© ê°ì†Œ
- Batch Size 32 + LR=1e-3 ì¡°í•©ì´ ìµœì 

---

# ğŸ“ 8. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°(ìš”ì•½)

```
PytorchProject/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # ì›ì²œ ë°ì´í„°
â”‚   â”œâ”€â”€ interim/            # ì¤‘ê°„ ì²˜ë¦¬ ê²°ê³¼
â”‚   â”œâ”€â”€ processed/          # ìµœì¢… ë³‘í•© + anomaly ê²°ê³¼
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/               # ë¡œë”©/ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ features/           # Feature ìƒì„± + KoBERT ì„ë² ë”©
â”‚   â”œâ”€â”€ models/             # AutoEncoder ëª¨ë¸ ì •ì˜
â”‚   â”œâ”€â”€ analysis/           # ì´ìƒì¹˜ ë¶„ì„/ë¦¬í¬íŠ¸ ìƒì„±
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ autoencoder/        # Best ëª¨ë¸ ì €ì¥
â”‚
â””â”€â”€ README.md
```

---

# ğŸ”— 9. í–¥í›„ ë°œì „ ë°©í–¥

- Transformer ê¸°ë°˜ ì‹œê³„ì—´ AutoEncoder ì ìš©  
- ë‰´ìŠ¤ ìš”ì•½ì— KoBART-Large or LLM Summarizer ì¶”ê°€  
- ì„¹í„°ë³„ ì´ìƒì¹˜ ë¶„ì„ ëª¨ë¸ í™•ì¥  
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ Online Anomaly Detection êµ¬ì¶•  

---

