import os
import json
import time
import datetime
import email.utils
import urllib.parse
import urllib.request
from pathlib import Path
from typing import List, Dict

import pandas as pd
from dotenv import load_dotenv

# ---------------------------------------------------------
# CONFIG
# ---------------------------------------------------------
RAW_DIR = Path(r"C:\MyProject\PytorchProject\data\raw\news")
RAW_DIR.mkdir(parents=True, exist_ok=True)

load_dotenv()

client_id = os.getenv("client_id")
client_secret = os.getenv("client_secret")

if not client_id or not client_secret:
    raise ValueError("NAVER_CLIENT_ID / NAVER_CLIENT_SECRET ê°’ì„ .envì— ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

# ---------------------------------------------------------
# NAVER API
# ---------------------------------------------------------
def naver_news_search(query: str, display=100, start=1):
    enc_query = urllib.parse.quote(query)
    url = (
        f"https://openapi.naver.com/v1/search/news?"
        f"query={enc_query}&display={display}&start={start}&sort=date"
    )

    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)

    response = urllib.request.urlopen(request)
    if response.getcode() != 200:
        print("Error Code:", response.getcode())
        return None

    return json.loads(response.read().decode("utf-8"))


def parse_pubdate(pubdate_str: str) -> datetime.datetime:
    """ë„¤ì´ë²„ pubDate â†’ datetime"""
    return email.utils.parsedate_to_datetime(pubdate_str)


# ---------------------------------------------------------
# ì›”ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
# ---------------------------------------------------------
def fetch_news_for_query_month(query: str, year: int, month: int) -> pd.DataFrame:
    """
    íŠ¹ì • ì›”(year-month) + íŠ¹ì • í‚¤ì›Œë“œ(query) ë‰´ìŠ¤ 1000ê±´ê¹Œì§€ ìˆ˜ì§‘
    """
    monthly_rows = []
    start = 1
    max_start = 1000
    display = 100

    # ì›”ë³„ ì¿¼ë¦¬ ìƒì„±
    q = f"{query} {year}ë…„ {month:02d}ì›”"

    while True:
        data = naver_news_search(q, display=display, start=start)
        if not data:
            break

        items = data.get("items", [])
        if not items:
            break

        for it in items:
            pub_dt = parse_pubdate(it["pubDate"])
            monthly_rows.append({
                "pub_datetime": pub_dt,
                "pub_date": pub_dt.date(),
                "query": query,
                "query_month": f"{year}-{month:02d}",
                "title": it.get("title"),
                "description": it.get("description"),
                "link": it.get("link"),
                "originallink": it.get("originallink"),
            })

        start += display
        if start > max_start:
            break

        time.sleep(0.2)

    df = pd.DataFrame(monthly_rows)
    if not df.empty:
        df = df.sort_values("pub_datetime").reset_index(drop=True)

    return df


# ---------------------------------------------------------
# ì›” ë¦¬ìŠ¤íŠ¸ ìƒì„±
# ---------------------------------------------------------
def generate_month_list(start_year: int, start_month: int, end_year: int, end_month: int):
    """
    2023-11 ~ 2025-10 ê°™ì€ ì›” ë¦¬ìŠ¤íŠ¸ ìƒì„±
    """
    months = []

    cur = datetime.date(start_year, start_month, 1)
    end = datetime.date(end_year, end_month, 1)

    while cur <= end:
        months.append((cur.year, cur.month))
        if cur.month == 12:
            cur = datetime.date(cur.year + 1, 1, 1)
        else:
            cur = datetime.date(cur.year, cur.month + 1, 1)

    return months


# ---------------------------------------------------------
# ì „ì²´ ìˆ˜ì§‘ ì‹¤í–‰
# ---------------------------------------------------------
def fetch_news_fixed_range():

    # ğŸ”¥ ê³ ì •ëœ ë‚ ì§œ ë²”ìœ„ (ë„ˆê°€ ì›í•˜ëŠ” ê¸°ì¤€)
    start_year, start_month = 2023, 11
    end_year, end_month = 2025, 10

    # ì›” ë¦¬ìŠ¤íŠ¸ ìƒì„±
    months = generate_month_list(start_year, start_month, end_year, end_month)

    # í‚¤ì›Œë“œ ëª©ë¡
    queries = ["í•œêµ­ ì¦ì‹œ", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥"]

    all_dfs = []

    for query in queries:
        for (y, m) in months:
            print(f"[FETCH] {query} / {y}-{m:02d}")

            df = fetch_news_for_query_month(query, y, m)

            if df.empty:
                print(f"    â†’ No data for {query} {y}-{m:02d}")
                continue

            # ì›”ë³„ ì €ì¥
            filename = f"news_{query.replace(' ', '_')}_{y}_{m:02d}.parquet"
            path = RAW_DIR / filename
            df.to_parquet(path, index=False)

            print(f"    â†’ Saved {len(df)} rows â†’ {path}")

            all_dfs.append(df)

    # ì „ì²´ ë³‘í•©
    if all_dfs:
        df_all = pd.concat(all_dfs, ignore_index=True)

        df_all = df_all.drop_duplicates(subset=["pub_datetime", "title"])
        df_all = df_all.sort_values("pub_datetime").reset_index(drop=True)

        merged_path = RAW_DIR / "naver_news_2023-11_2025-10.parquet"
        df_all.to_parquet(merged_path, index=False)

        print("\n==============================")
        print(f"[SAVED] Total merged news: {len(df_all)} rows")
        print(f"[PATH] {merged_path}")
        print("==============================")

        return merged_path

    print("No news collected.")
    return None


# ---------------------------------------------------------
# MAIN
# ---------------------------------------------------------
if __name__ == "__main__":
    fetch_news_fixed_range()
